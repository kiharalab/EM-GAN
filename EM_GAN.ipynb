{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiharalab/EM-GAN/blob/master/EM_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9VjY0UR7C_S"
      },
      "source": [
        "#EM-GAN: Improved Protein Structure Modeling Using Enhanced Cryo-EM Maps With 3D Deep Generative Networks\n",
        "<a href=\"https://github.com/marktext/marktext/releases/latest\">\n",
        "   <img src=\"https://img.shields.io/badge/platform-Linux%20%7C%20Mac%20-green\">\n",
        "   <img src=\"https://img.shields.io/badge/Language-python3-green\">\n",
        "   <img src=\"https://img.shields.io/badge/Language-C-green\">\n",
        "   <img src=\"https://img.shields.io/badge/dependencies-tested-green\">\n",
        "   <img src=\"https://img.shields.io/badge/licence-GNU-green\">\n",
        "</a>      \n",
        "\n",
        "EM-GAN is a computational tool, which enables capturing protein structure information from cryo-EM maps more effectively than raw maps. It is based on 3D deep learning. It is aimed to help protein structure modeling from cryo-EM maps. \n",
        "\n",
        "Cite : Sai Raghavendra Maddhuri Venkata Subramaniya, Genki Terashi & Daisuke Kihara. Improved Protein Structure Modeling Using Enhanced Cryo-EM Maps With 3D Deep Generative Networks. In submission (2022).\n",
        "Copyright (C) 2022 Sai Raghavendra Maddhuri Venkata Subramaniya, Genki Terashi, Daisuke Kihara, and Purdue University.\n",
        "\n",
        "License: GPL v3 for academic use. (For commercial use, please contact us for different licensing.)\n",
        "\n",
        "Contact: Daisuke Kihara (dkihara@purdue.edu)\n",
        "\n",
        "**We strongly suggest to use Google Chrome for EM-GAN Colab version. Other browsers such as Safari may raise errors when uploading or downloading files.**\n",
        "\n",
        "If you are using other browsers, disabling tracking protection may help resolve the errors when uploading or downloading files.\n",
        "\n",
        "For more details, see **<a href=\"#Instructions\">Instructions</a>** of the notebook and checkout the **[EM-GAN GitHub](https://github.com/kiharalab/EM-GAN)**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxhetscM97CY"
      },
      "source": [
        "# About EM-GAN\n",
        "![](https://github.com/kiharalab/EM-GAN/blob/master/data/git/architecture.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Overview of EM-GAN\n",
        "An increasing number of biological macromolecules have been solved with cryo-electron microscopy (cryo-EM). Over the past few years, the resolutions of density maps determined by cryo-EM have largely improved in general. However, there are still many cases where the resolution is not high enough to model molecular structures with standard computational tools. If the resolution obtained is near the empirical border line (3 - 4 Å), improvement in the map quality facilitates improved structure modeling. Here, we report that protein structure modeling can often be substantially improved by using a novel deep learning-based method that prepares an input cryo-EM map for modeling. The method uses a three-dimensional generative adversarial network, which learns density patterns of high and low-resolution density maps."
      ],
      "metadata": {
        "id": "MdPRqudcZXu-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lok4D8YC4lOb"
      },
      "source": [
        "# Instructions <a name=\"Instructions\"></a>\n",
        "\n",
        "**Quick start**\n",
        "\n",
        "1. Connect to a gpu machine by clicking the right top button **\"connect\"** in the notebook, then we can run EM-GAN under GPU support.\n",
        "2. Click the left running button in <a href=\"#Dependency\">Install Dependencies</a> to install dependencies.\n",
        "3. Upload your cryo-EM maps in mrc/map format by clicking the left running button in <a href=\"#Map\">Upload Cryo EM maps</a>. If you want to use our example, please skip this step. Here we suggest user to upload a cryo-EM map with **spacing 1** to save the running time.<br>\n",
        "Here is a simple instructions to do that via [ChimeraX](https://www.rbvi.ucsf.edu/chimerax/): <a name=\"ChimeraX\"></a>\n",
        "```\n",
        "1 open your map via chimeraX. \n",
        "2 In the bottom command line to type command: vol resample #1 spacing 1.0\n",
        "3 In ChimeraX, click \"save\", then choose \"MRC density map(*.mrc)\" in \"Files of type\", then in \"Map\" choose the resampled map, finally specify the file name and path to save.\n",
        "4 Then you can use the resampled map to upload\n",
        "```\n",
        "5. Running EM-GAN by by clicking the left running button in <a href=\"#Running\">Run EM-GAN</a>. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ipdca7TZRymE"
      },
      "source": [
        "# Run EM-GAN Online\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hLAAtBS39v0S",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cdc77bc-93f7-4029-c783-7657827169c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mrcfile==1.2.0\n",
            "  Downloading mrcfile-1.2.0-py2.py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from mrcfile==1.2.0) (1.21.6)\n",
            "Installing collected packages: mrcfile\n",
            "Successfully installed mrcfile-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting py3Dmol\n",
            "  Downloading py3Dmol-1.8.1-py2.py3-none-any.whl (6.5 kB)\n",
            "Installing collected packages: py3Dmol\n",
            "Successfully installed py3Dmol-1.8.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libfftw3-bin libfftw3-long3 libfftw3-quad3 libfftw3-single3\n",
            "Suggested packages:\n",
            "  libfftw3-doc\n",
            "The following NEW packages will be installed:\n",
            "  libfftw3-bin libfftw3-dev libfftw3-long3 libfftw3-quad3 libfftw3-single3\n",
            "0 upgraded, 5 newly installed, 0 to remove and 22 not upgraded.\n",
            "Need to get 3,766 kB of archives.\n",
            "After this operation, 21.2 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfftw3-long3 amd64 3.3.7-1 [308 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfftw3-quad3 amd64 3.3.7-1 [552 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfftw3-single3 amd64 3.3.7-1 [764 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfftw3-bin amd64 3.3.7-1 [32.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfftw3-dev amd64 3.3.7-1 [2,108 kB]\n",
            "Fetched 3,766 kB in 0s (28.4 MB/s)\n",
            "Selecting previously unselected package libfftw3-long3:amd64.\n",
            "(Reading database ... 123941 files and directories currently installed.)\n",
            "Preparing to unpack .../libfftw3-long3_3.3.7-1_amd64.deb ...\n",
            "Unpacking libfftw3-long3:amd64 (3.3.7-1) ...\n",
            "Selecting previously unselected package libfftw3-quad3:amd64.\n",
            "Preparing to unpack .../libfftw3-quad3_3.3.7-1_amd64.deb ...\n",
            "Unpacking libfftw3-quad3:amd64 (3.3.7-1) ...\n",
            "Selecting previously unselected package libfftw3-single3:amd64.\n",
            "Preparing to unpack .../libfftw3-single3_3.3.7-1_amd64.deb ...\n",
            "Unpacking libfftw3-single3:amd64 (3.3.7-1) ...\n",
            "Selecting previously unselected package libfftw3-bin.\n",
            "Preparing to unpack .../libfftw3-bin_3.3.7-1_amd64.deb ...\n",
            "Unpacking libfftw3-bin (3.3.7-1) ...\n",
            "Selecting previously unselected package libfftw3-dev:amd64.\n",
            "Preparing to unpack .../libfftw3-dev_3.3.7-1_amd64.deb ...\n",
            "Unpacking libfftw3-dev:amd64 (3.3.7-1) ...\n",
            "Setting up libfftw3-quad3:amd64 (3.3.7-1) ...\n",
            "Setting up libfftw3-single3:amd64 (3.3.7-1) ...\n",
            "Setting up libfftw3-long3:amd64 (3.3.7-1) ...\n",
            "Setting up libfftw3-bin (3.3.7-1) ...\n",
            "Setting up libfftw3-dev:amd64 (3.3.7-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "/content/EM-GAN\n"
          ]
        }
      ],
      "source": [
        "#@title Install dependencies <a name=\"Dependency\"></a>\n",
        "#@markdown Please make sure the notebook is already connected to **GPU**, EM-GAN needs GPU support to run.<br>\n",
        "#@markdown Click the right top button **\"connect\"**, then the notebook will automatically connect to a gpu machine\n",
        "%cd /content\n",
        "import urllib.request\n",
        "\n",
        "#get_url= urllib.request.urlopen('https://kiharalab.org/emsuites/daq_count.php?pwd=daq_dklab')\n",
        "#print(get_url)\n",
        "!pip install mrcfile==1.2.0 \n",
        "!pip install numpy>=1.19.4\n",
        "!pip install numba>=0.52.0\n",
        "!pip install torch>=1.6.0\n",
        "!pip install scipy>=1.6.0\n",
        "!pip install py3Dmol\n",
        "!pip install matplotlib\n",
        "!apt-get install libfftw3-dev\n",
        "!rm -rf EM-GAN\n",
        "!git clone https://github.com/kiharalab/EM-GAN --quiet\n",
        "%cd EM-GAN \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W3rR8yeEKu_R",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "1f2d4436-1361-483c-82ea-c843c5e45c1e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ebe836ca-23e9-4b75-b54e-0b4dd30cfd15\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ebe836ca-23e9-4b75-b54e-0b4dd30cfd15\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 6479_E.mrc to 6479_E.mrc\n",
            "User uploaded file \"6479_E.mrc\" with length 24198208 bytes\n",
            "Map save to /content/EM-GAN/engfwbrhrudmdsvkuuai/6479_E.mrc\n"
          ]
        }
      ],
      "source": [
        "#@title Input cryo-EM map <a name=\"Map\"></a>\n",
        "#@markdown If you choose to use author's example, please **skip** this. <br>\n",
        "#@markdown Otherwise, please follow the instructions to upload your cryo-EM map file.   \n",
        "#@markdown <br>\n",
        "#@markdown <br>Here we suggest user to upload a cryo-EM map with **spacing 1** to save the running time. Detailed instructions with ChimeraX is <a href=\"#ChimeraX\">ChimeraX resampling</a>\n",
        "#@markdown <br> **Support file format: .mrc, .mrc.gz**\n",
        "from google.colab import files\n",
        "import os\n",
        "import os.path\n",
        "import re\n",
        "import hashlib\n",
        "import random\n",
        "import string\n",
        "\n",
        "rand_letters = string.ascii_lowercase\n",
        "rand_letters = ''.join(random.choice(rand_letters) for i in range(20))\n",
        "use_author_example = False #@param {type:\"boolean\"}\n",
        "if not use_author_example:\n",
        "  root_dir = os.getcwd()\n",
        "  upload_dir = os.path.join(root_dir,rand_letters)\n",
        "  if not os.path.exists(upload_dir):\n",
        "    os.mkdir(upload_dir)\n",
        "  os.chdir(upload_dir)\n",
        "  map_input = files.upload()\n",
        "  for fn in map_input.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(map_input[fn])))\n",
        "    map_input_path = os.path.abspath(fn)\n",
        "    print(\"Map save to %s\"%map_input_path)\n",
        "  os.chdir(root_dir)\n",
        "else:\n",
        "  print(\"you have chosen to use author's example, you can not upload map files any more.\")\n",
        "  map_input_path = os.path.join(os.getcwd(),\"data\")\n",
        "  map_input_path = os.path.join(map_input_path,\"2788.mrc\")\n",
        "  contour=0.16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "KYfg7vIso0FH"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "import os.path\n",
        "import re\n",
        "import hashlib\n",
        "#@markdown Specify contour level <a name=\"Param\"></a>\n",
        "contour = '0.06' #@param {type:\"string\"}\n",
        "#@markdown ```author recommended contour level for the input map. Using contour level will not have any impact on the result, but can reduce the computation time. ```\n",
        "#@markdown <br>```default:0. Suggested Range: [0,author_contour]```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "SMcjEuKVLliT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290b54e8-6e5f-4c13-ee51-7fd93c609829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/kiharalab/EM-GAN\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n",
            "rm: cannot remove 'old_path': No such file or directory\n",
            "here\n",
            "2270\n",
            "2270\n",
            "18\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "0\n",
            "50431488\n",
            "./data_dir\n",
            "protein\n",
            "./data_dir/flag_dir/protein.flag\n",
            "protein done\n",
            "./data_dir/sr_hr_lr/\n",
            "2270\n",
            "./MergeMap -l ./tmpF\n",
          ]
        }
      ],
      "source": [
        "#@title Run EM-GAN <a name=\"Running\"></a>\n",
        "#@markdown Please allow 30 mins on average to get the output, since 3D input processing and inferencing takes some time. \n",
        "#@markdown <br>Our running time is directly correlated to the size of the structures. For example, a map with 260 * 260 * 260 can take 2 hours to finish.\n",
        "!git pull origin master\n",
        "!rm -r data_dir/\n",
        "old_path = os.path.join(os.getcwd(),\"data\")\n",
        "old_path = os.path.join(old_path, \"final.mrc\")\n",
        "!rm old_path\n",
        "!chmod +x data_prep/HLmapData\n",
        "!chmod +x MergeMap\n",
        "import mrcfile\n",
        "import numpy as np\n",
        "import shutil\n",
        "from numba import jit\n",
        "\n",
        "@jit(nopython=True,nogil=True)\n",
        "def interpolate_fast(data,data_new,size,iterator1,iterator2,iterator3,prev_voxel_size):\n",
        "    for i in range(1, iterator1, 1):\n",
        "        if(i%10==0):\n",
        "            print(\"Finished resizing %d/%d\"%(i,iterator1))\n",
        "        for j in range(1, iterator2, 1):\n",
        "            for k in range(1, iterator3, 1):\n",
        "                count = [int(i / prev_voxel_size), int(j / prev_voxel_size), int(k / prev_voxel_size)]\n",
        "                e1 = count[0] + 1\n",
        "                e2 = count[1] + 1\n",
        "                e3 = count[2] + 1\n",
        "\n",
        "                if (count[0] >= size[0] - 1):  # or count[1]>=size[1]-1 or count[2]>=size[2]-1 ):\n",
        "                    # print(count)\n",
        "                    e1 = count[0]\n",
        "                    continue\n",
        "                if (count[1] >= size[1] - 1):\n",
        "                    e2 = count[1]\n",
        "                    continue\n",
        "                if (count[2] >= size[2] - 1):\n",
        "                    e3 = count[2]\n",
        "                    continue\n",
        "                diff1 = [i - count[0] * prev_voxel_size, j - count[1] *prev_voxel_size, k - count[2] * prev_voxel_size]\n",
        "                diff2=[e1*prev_voxel_size-i,e2*prev_voxel_size-j,e3*prev_voxel_size-k]\n",
        "                # print(diff)\n",
        "                val1 = data[count[0], count[1], count[2]]\n",
        "                val2 = data[e1, count[1], count[2]]\n",
        "                val3 = data[e1, e2, count[2]]\n",
        "                val4 = data[count[0], e2, count[2]]\n",
        "                val5 = data[count[0], count[1], e3]\n",
        "                val6 = data[e1, count[1], e3]\n",
        "                val7 = data[e1, e2, e3]\n",
        "                val8 = data[count[0], e2, e3]\n",
        "                #val = (val1 + diff[0] * (val2 - val1) + diff[1] * (val4 - val1) + diff[2] * (val5 - val1) + diff[0] *\n",
        "                #       diff[1] * (val1 - val2 + val3 - val4) + diff[0] * diff[2] * (val1 - val2 - val5 + val6) + diff[\n",
        "                #           1] * diff[2] * (\n",
        "                #               val1 - val4 - val5 + val8) + diff[0] * diff[1] * diff[2] * (\n",
        "                #               val8 - val7 + val6 - val5 + val4 - val3 + val2 - val1))\n",
        "                u1=diff1[0]\n",
        "                u2=diff2[0]\n",
        "                v1=diff1[1]\n",
        "                v2=diff2[1]\n",
        "                w1=diff1[2]\n",
        "                w2=diff2[2]\n",
        "                val=(w2*(v1*(u1*val3+u2*val4)+v2*(u1*val2+u2*val1))+w1*(v1*(u1*val7+u2*val8)+v2*(u1*val6+u2*val5)))/(w1+w2)/(v1+v2)/(u1+u2)\n",
        "                data_new[i,j,k]=val\n",
        "    return data_new#np.float32(data_new)\n",
        "\n",
        "@jit(nopython=True,nogil=True)\n",
        "def interpolate_fast_general(data,data_new,size,iterator1,iterator2,iterator3,\n",
        "                             prev_voxel_size1,prev_voxel_size2,prev_voxel_size3):\n",
        "    for i in range(1, iterator1, 1):\n",
        "        if(i%10==0):\n",
        "            print(\"Finished resizing %d/%d\"%(i,iterator1))\n",
        "        for j in range(1, iterator2, 1):\n",
        "            for k in range(1, iterator3, 1):\n",
        "                count = [int(i / prev_voxel_size1), int(j / prev_voxel_size2), int(k / prev_voxel_size3)]\n",
        "                e1 = count[0] + 1\n",
        "                e2 = count[1] + 1\n",
        "                e3 = count[2] + 1\n",
        "\n",
        "                if (count[0] >= size[0] - 1):  # or count[1]>=size[1]-1 or count[2]>=size[2]-1 ):\n",
        "                    # print(count)\n",
        "                    e1 = count[0]\n",
        "                    continue\n",
        "                if (count[1] >= size[1] - 1):\n",
        "                    e2 = count[1]\n",
        "                    continue\n",
        "                if (count[2] >= size[2] - 1):\n",
        "                    e3 = count[2]\n",
        "                    continue\n",
        "                diff1 = [i - count[0] * prev_voxel_size1, j - count[1] *prev_voxel_size2, k - count[2] * prev_voxel_size3]\n",
        "                diff2 = [e1*prev_voxel_size1-i,e2*prev_voxel_size2-j,e3*prev_voxel_size3-k]\n",
        "                # print(diff)\n",
        "                val1 = data[count[0], count[1], count[2]]\n",
        "                val2 = data[e1, count[1], count[2]]\n",
        "                val3 = data[e1, e2, count[2]]\n",
        "                val4 = data[count[0], e2, count[2]]\n",
        "                val5 = data[count[0], count[1], e3]\n",
        "                val6 = data[e1, count[1], e3]\n",
        "                val7 = data[e1, e2, e3]\n",
        "                val8 = data[count[0], e2, e3]\n",
        "                #val = (val1 + diff[0] * (val2 - val1) + diff[1] * (val4 - val1) + diff[2] * (val5 - val1) + diff[0] *\n",
        "                #       diff[1] * (val1 - val2 + val3 - val4) + diff[0] * diff[2] * (val1 - val2 - val5 + val6) + diff[\n",
        "                #           1] * diff[2] * (\n",
        "                #               val1 - val4 - val5 + val8) + diff[0] * diff[1] * diff[2] * (\n",
        "                #               val8 - val7 + val6 - val5 + val4 - val3 + val2 - val1))\n",
        "                u1=diff1[0]\n",
        "                u2=diff2[0]\n",
        "                v1=diff1[1]\n",
        "                v2=diff2[1]\n",
        "                w1=diff1[2]\n",
        "                w2=diff2[2]\n",
        "                val=(w2*(v1*(u1*val3+u2*val4)+v2*(u1*val2+u2*val1))+w1*(v1*(u1*val7+u2*val8)+v2*(u1*val6+u2*val5)))/(w1+w2)/(v1+v2)/(u1+u2)\n",
        "                data_new[i,j,k]=val\n",
        "    return data_new#np.float32(data_new)\n",
        "\n",
        "def interpolate_slow(data,data_new,size,iterator1,iterator2,iterator3,prev_voxel_size):\n",
        "    for i in range(1, iterator1, 1):\n",
        "        if(i%10==0):\n",
        "            print(\"Finished resizing %d/%d\"%(i,iterator1))\n",
        "        for j in range(1, iterator2, 1):\n",
        "            for k in range(1, iterator3, 1):\n",
        "                count = [int(i / prev_voxel_size), int(j / prev_voxel_size), int(k / prev_voxel_size)]\n",
        "                e1 = count[0] + 1\n",
        "                e2 = count[1] + 1\n",
        "                e3 = count[2] + 1\n",
        "\n",
        "                if (count[0] >= size[0] - 1):  # or count[1]>=size[1]-1 or count[2]>=size[2]-1 ):\n",
        "                    # print(count)\n",
        "                    e1 = count[0]\n",
        "                    continue\n",
        "                if (count[1] >= size[1] - 1):\n",
        "                    e2 = count[1]\n",
        "                    continue\n",
        "                if (count[2] >= size[2] - 1):\n",
        "                    e3 = count[2]\n",
        "                    continue\n",
        "                diff1 = [i - count[0] * prev_voxel_size, j - count[1] *prev_voxel_size, k - count[2] * prev_voxel_size]\n",
        "                diff2=[e1*prev_voxel_size-i,e2*prev_voxel_size-j,e3*prev_voxel_size-k]\n",
        "                # print(diff)\n",
        "                val1 = data[count[0], count[1], count[2]]\n",
        "                val2 = data[e1, count[1], count[2]]\n",
        "                val3 = data[e1, e2, count[2]]\n",
        "                val4 = data[count[0], e2, count[2]]\n",
        "                val5 = data[count[0], count[1], e3]\n",
        "                val6 = data[e1, count[1], e3]\n",
        "                val7 = data[e1, e2, e3]\n",
        "                val8 = data[count[0], e2, e3]\n",
        "                #val = (val1 + diff[0] * (val2 - val1) + diff[1] * (val4 - val1) + diff[2] * (val5 - val1) + diff[0] *\n",
        "                #       diff[1] * (val1 - val2 + val3 - val4) + diff[0] * diff[2] * (val1 - val2 - val5 + val6) + diff[\n",
        "                #           1] * diff[2] * (\n",
        "                #               val1 - val4 - val5 + val8) + diff[0] * diff[1] * diff[2] * (\n",
        "                #               val8 - val7 + val6 - val5 + val4 - val3 + val2 - val1))\n",
        "                u1=diff1[0]\n",
        "                u2=diff2[0]\n",
        "                v1=diff1[1]\n",
        "                v2=diff2[1]\n",
        "                w1=diff1[2]\n",
        "                w2=diff2[2]\n",
        "                val=(w2*(v1*(u1*val3+u2*val4)+v2*(u1*val2+u2*val1))+w1*(v1*(u1*val7+u2*val8)+v2*(u1*val6+u2*val5)))/(w1+w2)/(v1+v2)/(u1+u2)\n",
        "                data_new[i,j,k]=val\n",
        "    return data_new\n",
        "\n",
        "def Reform_Map_Voxel(map_path,new_map_path):\n",
        "    print(\"here\")\n",
        "    if not os.path.exists(new_map_path):\n",
        "        with mrcfile.open(map_path,permissive=True) as mrc:\n",
        "            prev_voxel_size=mrc.voxel_size\n",
        "            #assert len(prev_voxel_size)==3\n",
        "\n",
        "            if not(prev_voxel_size['x']==prev_voxel_size['y'] and prev_voxel_size['x']==prev_voxel_size['z']):\n",
        "                print(\"Grid size of different axis is different, please specify --resize=1 in command line to call another slow process to deal with it!\")\n",
        "                exit(1)\n",
        "            prev_voxel_size=float(prev_voxel_size['x'])\n",
        "            nx, ny, nz, nxs, nys, nzs, mx, my, mz =\\\n",
        "                mrc.header.nx, mrc.header.ny, mrc.header.nz, \\\n",
        "                mrc.header.nxstart, mrc.header.nystart, mrc.header.nzstart,\\\n",
        "                mrc.header.mx, mrc.header.my, mrc.header.mz\n",
        "            orig = mrc.header.origin\n",
        "            print(\"Origin:\",orig)\n",
        "            print(\"Previous voxel size:\",prev_voxel_size)\n",
        "            data = mrc.data\n",
        "            data = np.swapaxes(data, 0, 2)\n",
        "            size = np.shape(data)\n",
        "            if (prev_voxel_size==1):\n",
        "                shutil.copy(map_path,new_map_path)\n",
        "                return new_map_path\n",
        "            if (prev_voxel_size < 1):\n",
        "                print(\"Grid size is smaller than 1, please specify --resize=1 in command line to call another slow process to deal with it!\")\n",
        "                exit(1)\n",
        "            it_val1 = int(np.floor(size[0] * prev_voxel_size))\n",
        "            it_val2 = int(np.floor(size[1] * prev_voxel_size))\n",
        "            it_val3 = int(np.floor(size[2] * prev_voxel_size))\n",
        "            print(\"Previouse size:\",size,\" Current map size:\",it_val1,it_val2,it_val3)\n",
        "            data_new = np.zeros([it_val1,it_val2,it_val3])\n",
        "            data_new[0, 0, 0] = data[0, 0, 0]\n",
        "            data_new[it_val1 - 1, it_val2 - 1, it_val3 - 1] = data[\n",
        "                size[0] - 1, size[1] - 1, size[2] - 1]\n",
        "            #iterator = Value('i', it_val)\n",
        "            #s = Value('d', float(prev_voxel_size))\n",
        "            #pool = Pool(3)\n",
        "            #out_1d = pool.map(interpolate,enumerate(np.reshape(data_new, (iterator.value * iterator.value * iterator.value,))))\n",
        "            #data_new = np.array(out_1d).reshape(iterator.value, iterator.value, iterator.value)\n",
        "            try:\n",
        "                data_new=interpolate_fast(data,data_new,size,it_val1,it_val2,it_val3,prev_voxel_size)\n",
        "            except:\n",
        "                data_new = np.zeros([it_val1, it_val2, it_val3])\n",
        "                data_new[0, 0, 0] = data[0, 0, 0]\n",
        "                data_new[it_val1 - 1, it_val2 - 1, it_val3 - 1] = data[\n",
        "                    size[0] - 1, size[1] - 1, size[2] - 1]\n",
        "                data_new = interpolate_slow(data, data_new, size, it_val1,it_val2,it_val3, prev_voxel_size)\n",
        "            data_new = np.swapaxes(data_new, 0, 2)\n",
        "            data_new=np.float32(data_new)\n",
        "            mrc_new = mrcfile.new(new_map_path, data=data_new, overwrite=True)\n",
        "            vsize = mrc_new.voxel_size\n",
        "            vsize.flags.writeable = True\n",
        "            vsize.x = 1.0\n",
        "            vsize.y = 1.0\n",
        "            vsize.z = 1.0\n",
        "            mrc_new.voxel_size = vsize\n",
        "            mrc_new.update_header_from_data()\n",
        "            mrc_new.header.nxstart = nxs * prev_voxel_size\n",
        "            mrc_new.header.nystart = nys * prev_voxel_size\n",
        "            mrc_new.header.nzstart = nzs * prev_voxel_size\n",
        "            mrc_new.header.mapc = mrc.header.mapc\n",
        "            mrc_new.header.mapr = mrc.header.mapr\n",
        "            mrc_new.header.maps = mrc.header.maps\n",
        "            mrc_new.header.origin = orig\n",
        "            mrc_new.update_header_stats()\n",
        "            mrc.print_header()\n",
        "            mrc_new.print_header()\n",
        "            mrc_new.close()\n",
        "            del data\n",
        "            del data_new\n",
        "           # del out_1d\n",
        "    return new_map_path\n",
        "\n",
        "new_map_path = os.path.join(os.getcwd(),\"data\")\n",
        "new_map_path = os.path.join(new_map_path,\"final.mrc\")\n",
        "Reform_Map_Voxel(map_input_path,new_map_path)\n",
        "!data_prep/HLmapData -a \"{new_map_path}\" -b \"{new_map_path}\" -A  \"{contour}\" -B \"{contour}\" -w 12 -s 4 >  protein_trimmap\n",
        "!python data_prep/generate_input.py protein_trimmap protein_data ./data_dir/\n",
        "!python test.py --res_blocks=5 --batch_size=128 --in_channels=32 --G_path=model/G_model --D_path=model/D_model --dir_path=data_dir/\n",
        "!python sr_dataprep.py\n",
        "!python avg_model.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdivYUPS4oaZ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Download EM-GAN Output <a name=\"Download\"></a>\n",
        "#@markdown Download modified EM map as Merged.mrc\n",
        "from google.colab import files\n",
        "import os\n",
        "download_path = os.path.join(os.getcwd(),\"Merged.mrc\")\n",
        "files.download(download_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gidk7Oaeido0"
      },
      "source": [
        "## Citation: <a name=\"Citation\"></a>\n",
        "\n",
        "Sai Raghavendra Maddhuri Venkata Subramaniya, Genki Terashi & Daisuke Kihara. Improved Protein Structure Modeling Using Enhanced Cryo-EM Maps With 3D Deep Generative Networks. In submission (2022)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
